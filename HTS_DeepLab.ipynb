{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#  Our Configuration\n",
        "# import the necessary packages\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# base path of the dataset\n",
        "DATASET_PATH = \"your path/tiled_images\"\n",
        "\n",
        "# define the path to the images and masks dataset\n",
        "IMAGE_DATASET_PATH = os.path.join(DATASET_PATH, \"images\")\n",
        "MASK_DATASET_PATH = os.path.join(DATASET_PATH, \"labels\")\n",
        "\n",
        "# define the test split\n",
        "TEST_SPLIT = 0.2\n",
        "\n",
        "# determine the device to be used for training and evaluation\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# determine if we will be pinning memory during data loading\n",
        "PIN_MEMORY = True if DEVICE == \"cuda\" else False\n",
        "\n",
        "MODEL = [\"deeplabv3_resnet50\", \"fcn_resnet101\"]\n",
        "# initialize learning rate, number of epochs to train for, and the\n",
        "# batch size\n",
        "INIT_LR = 0.01\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 26\n",
        "# define the input image dimensions\n",
        "INPUT_IMAGE_WIDTH = 224\n",
        "INPUT_IMAGE_HEIGHT = 224\n",
        "# define threshold to filter weak predictions\n",
        "THRESHOLD = 0.5\n",
        "# define the path to the base output directory\n",
        "BASE_OUTPUT = \"your path/output\"\n",
        "# define the path to the output serialized model, model training\n",
        "# plot, and testing image paths\n",
        "MODEL_PATH = os.path.join(BASE_OUTPUT, \"hts_deeplab.pth\")\n",
        "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot_hts_deeplab.png\"])\n",
        "TEST_PATHS = os.path.sep.join([BASE_OUTPUT, \"test_paths.txt\"])"
      ],
      "metadata": {
        "id": "KOQiH3ecZTR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Segmentation Dataset\n",
        "\n",
        "# import the necessary packages\n",
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "\tdef __init__(self, imagePaths, maskPaths, transforms):\n",
        "\t\t# store the image and mask filepaths, and augmentation\n",
        "\t\t# transforms\n",
        "\t\tself.imagePaths = imagePaths\n",
        "\t\tself.maskPaths = maskPaths\n",
        "\t\tself.transforms = transforms\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\t# return the number of total samples contained in the dataset\n",
        "\t\treturn len(self.imagePaths)\n",
        "\n",
        "\tdef __getitem__(self, idx):\n",
        "\t\t# grab the image path from the current index\n",
        "\t\timagePath = self.imagePaths[idx]\n",
        "\n",
        "\t\t# load the image from disk, swap its channels from BGR to RGB,\n",
        "\t\t# and read the associated mask from disk in grayscale mode\n",
        "\t\timage = cv2.imread(imagePath)\n",
        "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\t\tmask = cv2.imread(self.maskPaths[idx], 0)\n",
        "\n",
        "\t\t# check to see if we are applying any transformations\n",
        "\t\tif self.transforms is not None:\n",
        "\t\t\t# apply the transformations to both image and its mask\n",
        "\t\t\timage = self.transforms(image)\n",
        "\t\t\tmask =( self.transforms(mask))*255\n",
        "\n",
        "\t\t# return a tuple of the image and its mask\n",
        "\t\treturn (image, mask)"
      ],
      "metadata": {
        "id": "cXyxeLqB-zpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import transforms\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "fX7DzwYb-2r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the image and mask filepaths in a sorted manner\n",
        "imagePaths = sorted(list(paths.list_images(IMAGE_DATASET_PATH)))\n",
        "maskPaths = sorted(list(paths.list_images(MASK_DATASET_PATH)))\n",
        "# partition the data into training and testing splits using 80% of\n",
        "# the data for training and the remaining 20% for testing\n",
        "split = train_test_split(imagePaths, maskPaths,\n",
        "\ttest_size=TEST_SPLIT, random_state=42)\n",
        "# unpack the data split\n",
        "(trainImages, testImages) = split[:2]\n",
        "(trainMasks, testMasks) = split[2:]\n",
        "# write the testing image paths to disk so that we can use then\n",
        "# when evaluating/testing our model\n",
        "print(\"[INFO] saving testing image paths...\")\n",
        "f = open(TEST_PATHS, \"w\")\n",
        "f.write(\"\\n\".join(testImages))\n",
        "f.close()"
      ],
      "metadata": {
        "id": "cB6Y5ZOO-9D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define transformations\n",
        "transforms = transforms.Compose([transforms.ToPILImage(),\n",
        " \ttransforms.Resize((INPUT_IMAGE_HEIGHT,\n",
        "\t\tINPUT_IMAGE_WIDTH)),\n",
        "\ttransforms.ToTensor()])\n",
        "# create the train and test datasets\n",
        "trainDS = SegmentationDataset(imagePaths=trainImages, maskPaths=trainMasks,\n",
        "\ttransforms=transforms)\n",
        "testDS = SegmentationDataset(imagePaths=testImages, maskPaths=testMasks,\n",
        "    transforms=transforms)\n",
        "print(f\"[INFO] found {len(trainDS)} examples in the training set...\")\n",
        "print(f\"[INFO] found {len(testDS)} examples in the test set...\")\n",
        "# create the training and test data loaders\n",
        "trainLoader = DataLoader(trainDS, shuffle=True,\n",
        "\tbatch_size=BATCH_SIZE, pin_memory=PIN_MEMORY,\n",
        "\tnum_workers=os.cpu_count())\n",
        "testLoader = DataLoader(testDS, shuffle=False,\n",
        "\tbatch_size=BATCH_SIZE, pin_memory=PIN_MEMORY,\n",
        "\tnum_workers=os.cpu_count())\n",
        "\n"
      ],
      "metadata": {
        "id": "f2DCBkXK_APu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load(\"pytorch/vision:v0.10.0\", MODEL[0],\n",
        "\tpretrained=False)\n",
        "model.to(DEVICE)\n",
        "lossFunc = BCEWithLogitsLoss()\n",
        "opt = Adam(model.parameters(), lr=INIT_LR)\n",
        "# calculate steps per epoch for training and test set\n",
        "trainSteps = len(trainDS) // BATCH_SIZE\n",
        "testSteps = len(testDS) // BATCH_SIZE\n",
        "# initialize a dictionary to store training history\n",
        "H = {\"train_loss\": [], \"test_loss\": []}"
      ],
      "metadata": {
        "id": "DrqUHCKy_3qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "count_parameters(model)\n"
      ],
      "metadata": {
        "id": "zIfTmpcXiSZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over epochs\n",
        "print(\"[INFO] training the network...\")\n",
        "startTime = time.time()\n",
        "for e in tqdm(range(NUM_EPOCHS)):\n",
        "\t# set the model in training mode\n",
        "\tmodel.train()\n",
        "\t# initialize the total training and validation loss\n",
        "\ttotalTrainLoss = 0\n",
        "\ttotalTestLoss = 0\n",
        "\t# loop over the training set\n",
        "\tfor (i, (x, y)) in enumerate(trainLoader):\n",
        "\t\t# send the input to the device\n",
        "\t\t(x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
        "\t\t# perform a forward pass and calculate the training loss\n",
        "\t\tpred = model(x)[\"out\"]\n",
        "\t\tpred2 =pred[:,1:2,:,:]\n",
        "\t\tloss = lossFunc(pred2, y)\n",
        "\t\t# first, zero out any previously accumulated gradients, then\n",
        "\t\t# perform backpropagation, and then update model parameters\n",
        "\t\topt.zero_grad()\n",
        "\t\tloss.backward()\n",
        "\t\topt.step()\n",
        "\t\t# add the loss to the total training loss so far\n",
        "\t\ttotalTrainLoss += loss\n",
        "\t# switch off autograd\n",
        "\twith torch.no_grad():\n",
        "\t\t# set the model in evaluation mode\n",
        "\t\tmodel.eval()\n",
        "\t\t# loop over the validation set\n",
        "\t\tfor (x, y) in testLoader:\n",
        "\t\t\t# send the input to the device\n",
        "\t\t\t(x, y) = (x.to(DEVICE), y.to(DEVICE))\n",
        "\t\t\t# make the predictions and calculate the validation loss\n",
        "\t\t\tpred = model(x)[\"out\"]\n",
        "\t\t\tpred2 =pred[:,1:2,:,:]\n",
        "\t\t\ttotalTestLoss += lossFunc(pred2, y)\n",
        "\t# calculate the average training and validation loss\n",
        "\tavgTrainLoss = totalTrainLoss / trainSteps\n",
        "\tavgTestLoss = totalTestLoss / testSteps\n",
        "\t# update our training history\n",
        "\tH[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
        "\tH[\"test_loss\"].append(avgTestLoss.cpu().detach().numpy())\n",
        "\t# print the model training and validation information\n",
        "\tprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, NUM_EPOCHS))\n",
        "\tprint(\"Train loss: {:.6f}, Test loss: {:.4f}\".format(\n",
        "\t\tavgTrainLoss, avgTestLoss))\n",
        "# display the total time needed to perform the training\n",
        "endTime = time.time()\n",
        "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
        "\tendTime - startTime))"
      ],
      "metadata": {
        "id": "VGCBVcGjAlUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training loss\n",
        "plt.figure()\n",
        "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
        "plt.plot(H[\"test_loss\"], label=\"test_loss\")\n",
        "plt.title(\"Training Loss on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(PLOT_PATH)\n",
        "# serialize the model to disk\n",
        "torch.save(model, MODEL_PATH)"
      ],
      "metadata": {
        "id": "PF0xHSNACITE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import jaccard_score\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def prepare_plot(origImage, origMask, predMask):\n",
        "\t# initialize our figure\n",
        "\tfigure, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 10))\n",
        "\t# plot the original image, its mask, and the predicted mask\n",
        "\tax[0].imshow(origImage)\n",
        "\tax[1].imshow(origMask)\n",
        "\tax[2].imshow(predMask)\n",
        "\t# set the titles of the subplots\n",
        "\tax[0].set_title(\"Image\")\n",
        "\tax[1].set_title(\"Original Mask\")\n",
        "\tax[2].set_title(\"Predicted Mask\")\n",
        "\n",
        "\t# set the layout of the figure and display it\n",
        "\tfigure.tight_layout()\n",
        "\tfigure.show()"
      ],
      "metadata": {
        "id": "cu2xiMkTiKdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai"
      ],
      "metadata": {
        "id": "4Q_-raXGijF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from monai.metrics.utils import get_mask_edges, get_surface_distance\n",
        "\n",
        "def hausdorff(y_true, y_pred):\n",
        "    h, w = 224,224\n",
        "    max_dist = np.sqrt(w ** 2 + h ** 2)\n",
        "    (edges_pred, edges_gt) = get_mask_edges(y_pred, y_true)\n",
        "    surface_distance = get_surface_distance(edges_pred, edges_gt,\n",
        "                                            distance_metric=\"euclidean\")\n",
        "    if surface_distance.shape == (0,):\n",
        "        return 1.0\n",
        "    dist = np.max(surface_distance)\n",
        "    if dist > max_dist:\n",
        "        return 0.0\n",
        "    return dist / max_dist"
      ],
      "metadata": {
        "id": "BKknM_rcimDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metri(true_masks, predicted_masks):\n",
        "  iou = jaccard_score(true_masks, predicted_masks, average='weighted')\n",
        "  dice_coefficient = 2*iou / (1 + iou)\n",
        "  tp=(true_masks*predicted_masks).sum()\n",
        "  tn=(np.logical_not(true_masks)*np.logical_not(predicted_masks)).sum()\n",
        "  fn=((true_masks)*np.logical_not(predicted_masks)).sum()\n",
        "  fp=(np.logical_not(true_masks)*(predicted_masks)).sum()\n",
        "  recall=tp/(tp+fn)\n",
        "  precison=tp/(tp+fp)\n",
        "  accuracy=(tp+tn)/(tp+tn+fp+fn)\n",
        "  hd95=hausdorff(true_masks,predicted_masks)\n",
        "\n",
        "  return accuracy,iou,dice_coefficient,recall,precison,hd95"
      ],
      "metadata": {
        "id": "_RsPTVatipTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(model, imagePath):\n",
        "\t# set model to evaluation mode\n",
        "\tmodel.eval()\n",
        "\t# turn off gradient tracking\n",
        "\twith torch.no_grad():\n",
        "\t\t# load the image from disk, swap its color channels, cast it\n",
        "\t\t# to float data type, and scale its pixel values\n",
        "\t\timage = cv2.imread(imagePath)\n",
        "\t\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\t\timage = image.astype(\"float32\") / 255.0\n",
        "\t\t# resize the image and make a copy of it for visualization\n",
        "\t\timage = cv2.resize(image, (224, 224))\n",
        "\t\torig = image.copy()\n",
        "\t\t# find the filename and generate the path to ground truth\n",
        "\t\t# mask\n",
        "\t\tfilename = imagePath.split(os.path.sep)[-1]\n",
        "\t\tgroundTruthPath = os.path.join(MASK_DATASET_PATH,\n",
        "\t\t\tfilename.replace('bmp', 'tif'))\n",
        "\t\t# load the ground-truth segmentation mask in grayscale mode\n",
        "\t\t# and resize it\n",
        "\t\tgtMask = cv2.imread(groundTruthPath, 0)\n",
        "\n",
        "\t\tgtMask = cv2.resize(gtMask, (INPUT_IMAGE_HEIGHT,INPUT_IMAGE_HEIGHT))\n",
        "\n",
        "\t\t# make the channel axis to be the leading one, add a batch\n",
        "\t\t# dimension, create a PyTorch tensor, and flash it to the\n",
        "\t\t# current device\n",
        "\t\timage = np.transpose(image, (2, 0, 1))\n",
        "\t\timage = np.expand_dims(image, 0)\n",
        "\t\timage = torch.from_numpy(image).to(DEVICE)\n",
        "\t\t# make the prediction, pass the results through the sigmoid\n",
        "\t\t# function, and convert the result to a NumPy array\n",
        "\t\tpredMask = model(image)[\"out\"]\n",
        "\t\tpredMask = predMask[:,1:2,:,:]\n",
        "\t\tpredMask = torch.sigmoid(predMask)\n",
        "\t\tpredMask = predMask.cpu().numpy()\n",
        "\t\t# filter out the weak predictions and convert them to integers\n",
        "\t\tpredMask = (predMask > THRESHOLD)\n",
        "\t\tpredMask = predMask.astype(np.uint8)\n",
        "\t\t# prepare a plot for visualization\n",
        "\n",
        "\t\tprepare_plot(orig, gtMask, predMask[0,0,:,:])\n",
        "\t\treturn gtMask, predMask[0,0,:,:]\n",
        "# load the image paths in our testing file and randomly select 10\n",
        "# image paths\n",
        "print(\"[INFO] loading up test image paths...\")\n",
        "imagePaths = open(TEST_PATHS).read().strip().split(\"\\n\")\n",
        "# load our model from disk and flash it to the current device\n",
        "print(\"[INFO] load up model...\")\n",
        "model = torch.hub.load(\"pytorch/vision:v0.10.0\", MODEL[0],\n",
        "\tpretrained=False)\n",
        "model = torch.load(MODEL_PATH).to(DEVICE)\n",
        "acc=[]\n",
        "iou=[]\n",
        "dice=[]\n",
        "recall=[]\n",
        "prec=[]\n",
        "HD95=[]\n",
        "# iterate over the randomly selected test image paths\n",
        "for path in imagePaths:\n",
        "\tprint(path)\n",
        "\tmyMask,myPred=make_predictions(model, path)\n",
        "\tacc1,iou1,dice1,recall1,prec1,hausdorffdis1=metri(myMask,myPred)\n",
        "\tprint(acc1)\n",
        "\tprint(iou1)\n",
        "\tprint(dice1)\n",
        "\tprint(recall1)\n",
        "\tprint(prec1)\n",
        "\tprint(hausdorffdis1)\n",
        "\n",
        "\tacc.append(acc1)\n",
        "\tiou.append(iou1)\n",
        "\tdice.append(dice1)\n",
        "\trecall.append(recall1)\n",
        "\tprec.append(prec1)\n",
        "\tHD95.append(hausdorffdis1)\n",
        "\t# make predictions and visualize the results\n",
        "print(f\"acc: {np.mean(acc)} var ={np.var(acc)}\")\n",
        "print(f\"jaccard: {np.mean(iou) } var ={np.var(iou)}\")\n",
        "print(f\"Dice: {np.mean(dice)} var ={np.var(dice)}\")\n",
        "print(f\"Recall: {np.mean(recall)} var ={np.var(recall)}\")\n",
        "print(f\"Precison: {np.mean(prec)} var ={np.var(prec)}\")\n",
        "print(f\"Hausdorff distance: {np.mean(HD95)} var ={np.var(HD95)}\")"
      ],
      "metadata": {
        "id": "ML1UsZqnitq6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}